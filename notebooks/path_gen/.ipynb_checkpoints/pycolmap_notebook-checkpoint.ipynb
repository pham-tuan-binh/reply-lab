{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Structure from Motion with pycolmap\n",
    "\n",
    "This notebook demonstrates how to perform incremental Structure from Motion (SfM) on your own images using pycolmap. The process involves:\n",
    "\n",
    "1. Importing necessary libraries\n",
    "2. Setting up paths for your image folder\n",
    "3. Extracting features from images\n",
    "4. Matching features between images\n",
    "5. Running incremental mapping with a progress bar\n",
    "6. Visualizing and analyzing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import enlighten\n",
    "import pycolmap\n",
    "from pycolmap import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "output_path = Path(\"sfm_output/\")\n",
    "image_path = Path(\"YOUR_IMAGE_FOLDER\")  # Replace with your image folder path\n",
    "database_path = output_path / \"database.db\"\n",
    "sfm_path = output_path / \"sfm\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.set_log_destination(logging.INFO, output_path / \"INFO.log.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define helper function for incremental mapping with progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_mapping_with_pbar(database_path, image_path, sfm_path):\n",
    "    num_images = pycolmap.Database(database_path).num_images\n",
    "    with enlighten.Manager() as manager:\n",
    "        with manager.counter(\n",
    "            total=num_images, desc=\"Images registered:\"\n",
    "        ) as pbar:\n",
    "            pbar.update(0, force=True)\n",
    "            reconstructions = pycolmap.incremental_mapping(\n",
    "                database_path,\n",
    "                image_path,\n",
    "                sfm_path,\n",
    "                initial_image_pair_callback=lambda: pbar.update(2),\n",
    "                next_image_callback=lambda: pbar.update(1),\n",
    "            )\n",
    "    return reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature extraction and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete database if it exists\n",
    "if database_path.exists():\n",
    "    database_path.unlink()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "pycolmap.set_random_seed(0)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "pycolmap.extract_features(database_path, image_path)\n",
    "print(\"Feature extraction completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match features\n",
    "print(\"Matching features...\")\n",
    "pycolmap.match_exhaustive(database_path)\n",
    "print(\"Feature matching completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run incremental mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous reconstruction results if they exist\n",
    "if sfm_path.exists():\n",
    "    shutil.rmtree(sfm_path)\n",
    "sfm_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Run incremental mapping\n",
    "print(\"Running incremental mapping...\")\n",
    "reconstructions = incremental_mapping_with_pbar(database_path, image_path, sfm_path)\n",
    "print(\"Incremental mapping completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary for each reconstruction\n",
    "for idx, rec in reconstructions.items():\n",
    "    print(f\"Reconstruction #{idx}:\")\n",
    "    print(rec.summary())\n",
    "    print(f\"  Number of images: {rec.num_reg_images()}\")\n",
    "    print(f\"  Number of points: {rec.num_points3D()}\")\n",
    "    print(f\"  Mean track length: {rec.mean_track_length()}\")\n",
    "    print(f\"  Mean observations per image: {rec.mean_observations_per_image()}\")\n",
    "    print(f\"  Mean reprojection error: {rec.mean_reprojection_error()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize camera positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cameras(reconstruction):\n",
    "    \"\"\"Plot camera positions and orientations.\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Get camera centers and orientations\n",
    "    centers = []\n",
    "    directions = []\n",
    "    \n",
    "    for image_id, image in reconstruction.images.items():\n",
    "        cam = reconstruction.cameras[image.camera_id]\n",
    "        \n",
    "        # Camera center\n",
    "        center = image.tvec\n",
    "        centers.append(center)\n",
    "        \n",
    "        # Camera orientation (pointing direction)\n",
    "        R = image.qvec2rotmat()\n",
    "        direction = -R[:, 2]  # Negative z-axis is the viewing direction\n",
    "        directions.append(direction)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    centers = np.array(centers)\n",
    "    directions = np.array(directions)\n",
    "    \n",
    "    # Plot camera positions\n",
    "    ax.scatter(centers[:, 0], centers[:, 1], centers[:, 2], c='blue', marker='o', label='Camera Centers')\n",
    "    \n",
    "    # Plot camera viewing directions\n",
    "    scale = np.max(np.ptp(centers, axis=0)) * 0.1  # Scale arrows to 10% of the scene size\n",
    "    for center, direction in zip(centers, directions):\n",
    "        ax.quiver(center[0], center[1], center[2], \n",
    "                  direction[0] * scale, direction[1] * scale, direction[2] * scale,\n",
    "                  color='red', arrow_length_ratio=0.3)\n",
    "    \n",
    "    # Plot 3D points if they exist\n",
    "    if reconstruction.points3D:\n",
    "        points = np.array([point.xyz for point in reconstruction.points3D.values()])\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='green', marker='.', alpha=0.1, s=1, label='3D Points')\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.max(np.ptp(centers, axis=0))\n",
    "    mid_x = np.mean(centers[:, 0])\n",
    "    mid_y = np.mean(centers[:, 1])\n",
    "    mid_z = np.mean(centers[:, 2])\n",
    "    ax.set_xlim(mid_x - max_range/2, mid_x + max_range/2)\n",
    "    ax.set_ylim(mid_y - max_range/2, mid_y + max_range/2)\n",
    "    ax.set_zlim(mid_z - max_range/2, mid_z + max_range/2)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Camera Positions and 3D Points')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the largest reconstruction\n",
    "if reconstructions:\n",
    "    # Find the reconstruction with the most images\n",
    "    largest_idx = max(reconstructions.keys(), key=lambda idx: reconstructions[idx].num_reg_images())\n",
    "    largest_reconstruction = reconstructions[largest_idx]\n",
    "    print(f\"Visualizing reconstruction #{largest_idx} with {largest_reconstruction.num_reg_images()} images\")\n",
    "    plot_cameras(largest_reconstruction)\n",
    "else:\n",
    "    print(\"No reconstructions were created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom visualization of image connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database to analyze image connectivity\n",
    "db = pycolmap.Database(database_path)\n",
    "\n",
    "# Get all images\n",
    "images = db.execute_query(\"SELECT image_id, name FROM images\")\n",
    "image_id_to_name = {image_id: name for image_id, name in images}\n",
    "\n",
    "# Get matches between images\n",
    "matches = db.execute_query(\"SELECT pair_id, rows FROM matches WHERE rows > 0\")\n",
    "\n",
    "# Create a graph of image connectivity\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (images)\n",
    "for image_id, name in image_id_to_name.items():\n",
    "    # Use just the filename without path\n",
    "    short_name = Path(name).name\n",
    "    G.add_node(image_id, name=short_name)\n",
    "\n",
    "# Add edges (matches)\n",
    "for pair_id, num_matches in matches:\n",
    "    # Convert pair_id to image_id1, image_id2\n",
    "    # Using pycolmap's function to decode pair_id\n",
    "    image_id1, image_id2 = pycolmap.pair_id_to_image_ids(pair_id)\n",
    "    \n",
    "    # Only add edge if both images exist (should always be true)\n",
    "    if image_id1 in image_id_to_name and image_id2 in image_id_to_name:\n",
    "        G.add_edge(image_id1, image_id2, weight=num_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the image connectivity graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Position nodes using force-directed layout\n",
    "pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "\n",
    "# Get edge weights for visualization\n",
    "edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "max_weight = max(edge_weights)\n",
    "normalized_weights = [3 * w / max_weight for w in edge_weights]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, width=normalized_weights, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, labels=nx.get_node_attributes(G, 'name'), font_size=8)\n",
    "\n",
    "plt.title(\"Image Connectivity Graph (Edge Width = Number of Matches)\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export reconstruction to other formats (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to PLY format (can be viewed in MeshLab, CloudCompare, etc.)\n",
    "if reconstructions:\n",
    "    for idx, rec in reconstructions.items():\n",
    "        ply_path = output_path / f\"reconstruction_{idx}.ply\"\n",
    "        rec.export_PLY(str(ply_path))\n",
    "        print(f\"Exported reconstruction #{idx} to {ply_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced: Custom mapping parameters (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_incremental_mapping():\n",
    "    # Define custom mapping options\n",
    "    mapper_options = pycolmap.IncrementalMapperOptions()\n",
    "    mapper_options.min_model_size = 3  # Minimum number of registered images\n",
    "    mapper_options.max_model_overlap = 20  # Maximum number of overlapping images for different models\n",
    "    mapper_options.init_min_num_inliers = 50  # Minimum number of inliers for the initial pair\n",
    "    mapper_options.abs_pose_min_num_inliers = 30  # Minimum number of inliers for absolute pose estimation\n",
    "    \n",
    "    # Triangulation options\n",
    "    mapper_options.triangulation_options.min_angle = 2.0  # Minimum triangulation angle in degrees\n",
    "    mapper_options.triangulation_options.min_tri_angle = 6.0  # Minimum triangulation angle for creating new points\n",
    "    \n",
    "    # Ba (Bundle Adjustment) options\n",
    "    mapper_options.ba_global_options.num_iterations = 50  # Number of iterations for global bundle adjustment\n",
    "    \n",
    "    # Create new output path for custom reconstruction\n",
    "    custom_sfm_path = output_path / \"custom_sfm\"\n",
    "    if custom_sfm_path.exists():\n",
    "        shutil.rmtree(custom_sfm_path)\n",
    "    custom_sfm_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"Running custom incremental mapping...\")\n",
    "    custom_reconstructions = pycolmap.incremental_mapping(\n",
    "        database_path, \n",
    "        image_path, \n",
    "        custom_sfm_path,\n",
    "        options=mapper_options\n",
    "    )\n",
    "    print(\"Custom incremental mapping completed\")\n",
    "    \n",
    "    # Print summary\n",
    "    for idx, rec in custom_reconstructions.items():\n",
    "        print(f\"Custom reconstruction #{idx}: {rec.summary()}\")\n",
    "    \n",
    "    return custom_reconstructions\n",
    "\n",
    "# Uncomment the following line to run custom mapping\n",
    "# custom_reconstructions = run_custom_incremental_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Additional tips and troubleshooting\n",
    "\n",
    "### If your reconstruction fails or has poor quality:\n",
    "\n",
    "1. **Image quality**: Make sure your images are sharp, well-lit, and have good texture and overlap\n",
    "2. **Number of images**: SfM works best with many overlapping images (>10)\n",
    "3. **Camera motion**: Make sure the scene is captured from different viewpoints\n",
    "4. **Feature extraction options**: You can adjust the feature extraction parameters like below:\n",
    "   ```python\n",
    "   options = pycolmap.SiftExtractionOptions()\n",
    "   options.estimate_affine_shape = True\n",
    "   options.domain_size_pooling = True\n",
    "   pycolmap.extract_features(database_path, image_path, options=options)\n",
    "   ```\n",
    "5. **Matching options**: Try different matching strategies\n",
    "   ```python\n",
    "   # For sequential matching (works well for video or sequential image capture)\n",
    "   pycolmap.match_sequential(database_path, overlap=10)\n",
    "   \n",
    "   # For vocabulary tree matching (faster than exhaustive for large datasets)\n",
    "   pycolmap.match_vocab_tree(database_path, vocab_tree_path)\n",
    "   ```\n",
    "6. **Initial image pair**: You can specify a good initial image pair if you know one\n",
    "   ```python\n",
    "   options = pycolmap.IncrementalMapperOptions()\n",
    "   options.init_image_id1 = 1  # First image ID\n",
    "   options.init_image_id2 = 2  # Second image ID\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}